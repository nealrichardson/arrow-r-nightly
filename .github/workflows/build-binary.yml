name: Binary C++ libraries

on:
  schedule:
    - cron: |
        0 1 * * *
  push:
    paths:
      - '.github/workflows/build-binary.yml'
      - 'linux/*'
      - s3-upload.py
      - bintray-upload.sh
      - up-date-description.sh
  # On tag too?

jobs:
  linux:
    name: C++ Binary ${{ matrix.config.os }}-${{ matrix.config.version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        config:
        - { os: ubuntu, version: '16.04'}
        - { os: ubuntu, version: '18.04'}
        - { os: debian, version: '9'}
        - { os: debian, version: '10'}
        - { os: centos, version: '7'}
        - { os: centos, version: '8'}
    env:
      VERSION: ${{ matrix.config.version }}
    steps:
      - name: Checkout arrow-r-nightly
        uses: actions/checkout@v2
      - name: Clone apache/arrow and checkout at date
        shell: bash
        run: |
          cd linux
          git clone https://github.com/apache/arrow
          cd arrow
          git checkout `git rev-list -n 1 --before="00:00" master`
      - name: Build
        shell: bash
        run: |
          cd linux
          docker-compose build ${{ matrix.config.os }}
          docker-compose run ${{ matrix.config.os }}
      - name: Set up Python (for S3 upload)
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'
      - name: Install Boto
        run: |
          python -m pip install boto3
      - name: Bundle and upload
        env:
          BINTRAY_APIKEY: ${{ secrets.BINTRAY_APIKEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        shell: bash
        run: |
          cd linux/arrow/r
          export DATE=$(date -d yesterday +%Y%m%d)
          source ../../../up-date-description.sh
          VERSION=$(grep ^Version DESCRIPTION | sed s/Version:\ //)
          export PKG_FILE="arrow-${VERSION}.zip"
          cd libarrow/dist
          # These files were created by the docker user so we have to sudo to get them
          sudo -E zip -r $PKG_FILE lib/*.a include/
          export REPO_PATH=/libarrow/bin/${{ matrix.config.os }}-${{ matrix.config.version }}
          sudo -E bash ../../../../../bintray-upload.sh
          # Or, upload to S3
          # python ../../../../../s3-upload.py $PKG_FILE $REPO_PATH
  windows:
    name: C++ Binary Windows RTools (35 and 40)
    runs-on: windows-latest
    steps:
      - run: git config --global core.autocrlf false
      - name: Checkout Arrow
        uses: actions/checkout@v2
        with:
          fetch-depth: 0
      - name: Clone apache/arrow and checkout at date
        shell: bash
        run: |
          git clone https://github.com/apache/arrow
          cd arrow
          git checkout `git rev-list -n 1 --before="00:00" master`
          cd r
          export DATE=$(date -d yesterday +%Y%m%d)
          source ../../up-date-description.sh
      # First build with the new toolchain
      - uses: r-lib/actions/setup-r@master
        with:
          rtools-version: 40
          r-version: '4.0'
          Ncpus: 2
      - name: Build Arrow C++ with rtools40
        shell: bash
        env:
          ARROW_HOME: "arrow"
        run: arrow/ci/scripts/r_windows_build.sh
      - name: Clean up so we can build again
        shell: bash
        run: |
          rm -rf pkg
          rm -rf src
          pacman --noconfirm -R mingw-w64-{i686,x86_64}-{cmake,boost,openssl,thrift,snappy,lz4,zstd}
      # Now build with the old toolchain
      - uses: r-lib/actions/setup-r@master
        with:
          rtools-version: 35
          r-version: '3.6'
          Ncpus: 2
      - name: Build Arrow C++ with rtools35
        shell: bash
        env:
          ARROW_HOME: "arrow"
          RTOOLS_VERSION: 35
        run: arrow/ci/scripts/r_windows_build.sh
      - name: Set up Python (for S3 upload)
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'
      - name: Install Boto
        run: |
          python -m pip install boto3
      - name: Upload
        env:
          BINTRAY_APIKEY: ${{ secrets.BINTRAY_APIKEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        shell: bash
        run: |
          cd build
          export PKG_FILE=$(ls arrow-*.zip)
          export REPO_PATH=/libarrow/bin/windows
          source ../bintray-upload.sh
          # Or, upload to S3
          # python ../s3-upload.py $PKG_FILE $REPO_PATH
